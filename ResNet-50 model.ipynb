{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet-50 model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rH4XmErYj5wm"},"source":["# ResNet-50 Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MkoGLH_Tj5wn"},"source":["## Imports"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ORj09gnrj5wp","colab":{}},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n","import time\n","import torch\n","import base64\n","from IPython.display import HTML\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","%matplotlib inline\n","from torchvision import models\n","\n","if torch.cuda.is_available():\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgvFdj2ZGgno","colab_type":"code","outputId":"f49c42df-df91-46e0-bbf8-1ff7912cbc3f","executionInfo":{"status":"ok","timestamp":1557375748166,"user_tz":300,"elapsed":621,"user":{"displayName":"Ruoyi Cai","photoUrl":"","userId":"09261510786157090794"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YIrKAqPK1hvQ","colab_type":"text"},"source":["## Settings"]},{"cell_type":"code","metadata":{"id":"qlf84vQr1h3Q","colab_type":"code","colab":{}},"source":["##########################\n","### SETTINGS\n","##########################\n","\n","# Hyperparameters\n","RANDOM_SEED = 1\n","LEARNING_RATE = 0.1\n","NUM_EPOCHS = 30\n","\n","# Architecture\n","NUM_CLASSES = 45\n","BATCH_SIZE = 256\n","DEVICE = 'cuda:0' # default GPU device"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7BjFAwjajhb","colab_type":"text"},"source":["## Custom Dataset Class"]},{"cell_type":"code","metadata":{"id":"49XHGd-5aq6X","colab_type":"code","colab":{}},"source":["class MyDataset_RGB(Dataset):\n","\n","    def __init__(self, csv_path, img_dir, transform=None):\n","    \n","        df = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.img_names = df['File Name']\n","        self.y = df['Class Label']\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir,\n","                                      self.img_names[index]))\n","        \n","        # make 1 color channel to 3 \n","        ary = np.array(img)\n","        if len(ary.shape) < 3:\n","          ary = np.stack((ary,)*3,axis=-1)\n","          img = Image.fromarray(ary, 'RGB')\n","                    \n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        label = self.y[index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8l0JBVDsrBe","colab_type":"code","colab":{}},"source":["class MyDataset_Binary(Dataset):\n","\n","    def __init__(self, csv_path, img_dir, transform=None):\n","    \n","        df = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.img_names = df['File Name']\n","        self.y = df['Class Label']\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir,\n","                                      self.img_names[index]))\n","        \n","        img=img.convert(\"L\")\n","        threshold = 128\n","        # If pixel value smaller than threshold, return 0. Otherwise return 1.\n","        filter_func = lambda x: 0 if x < threshold else 1\n","        img=img.point(filter_func, \"1\")\n","          \n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        label = self.y[index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Franl-QbcSjN","colab_type":"code","colab":{}},"source":["class MyDataset_Grayscale(Dataset):\n","\n","    def __init__(self, csv_path, img_dir, transform=None):\n","    \n","        df = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.img_names = df['File Name']\n","        self.y = df['Class Label']\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir,\n","                                      self.img_names[index]))\n","                  \n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        label = self.y[index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4aPg7Eu2dpT-","colab_type":"text"},"source":["## Data Augmentation"]},{"cell_type":"markdown","metadata":{"id":"enQdCCBBCdSO","colab_type":"text"},"source":["### Transformation for grayscale images"]},{"cell_type":"code","metadata":{"id":"mfZlTcb7dscm","colab_type":"code","colab":{}},"source":["train_transforms_Grayscale = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.RandomAffine(degrees=(-20, 20), translate=(0.15, 0.15),\n","                                        resample=Image.BILINEAR),\n","    transforms.Resize(size=(40, 40)),\n","    transforms.RandomCrop(32),\n","    transforms.ToTensor()\n","])\n","\n","valid_transforms_Grayscale = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.Resize(size=(40, 40)),\n","    transforms.CenterCrop(32),\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_Grayscale = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.Resize(size=(40, 40)),\n","    transforms.CenterCrop(32),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LVWPyZtUCeLo","colab_type":"text"},"source":["### Transformation for binary images\n"]},{"cell_type":"code","metadata":{"id":"E4c6BJWuyhRq","colab_type":"code","colab":{}},"source":["train_transforms_Binary = transforms.Compose([\n","    transforms.RandomAffine(degrees=(-20, 20), translate=(0.15, 0.15),\n","                                        resample=Image.BILINEAR),\n","    transforms.Resize(size=(40, 40)),\n","    transforms.RandomCrop(32),\n","    transforms.ToTensor()\n","])\n","\n","valid_transforms_Binary = transforms.Compose([\n","    transforms.Resize(size=(40, 40)),\n","    transforms.CenterCrop(32),\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_Binary = transforms.Compose([\n","    transforms.Resize(size=(40, 40)),\n","    transforms.CenterCrop(32),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y1mNY9VKChrq","colab_type":"text"},"source":["### Transformation for RGB images"]},{"cell_type":"code","metadata":{"id":"uDR0oyymffRV","colab_type":"code","colab":{}},"source":["train_transforms_RGB = transforms.Compose([\n","    transforms.RandomAffine(degrees=(-20, 20), translate=(0.15, 0.15),\n","                                        resample=Image.BILINEAR),\n","    transforms.Resize(size=(40, 40)),\n","    transforms.RandomCrop(32),\n","    transforms.ToTensor()\n","])\n","\n","valid_transforms_RGB = transforms.Compose([\n","    transforms.Resize(size=(40, 40)),\n","    transforms.CenterCrop(32),\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_RGB = transforms.Compose([\n","    transforms.Resize(size=(40, 40)),\n","    transforms.CenterCrop(32),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EQsThgTmh23y","colab_type":"text"},"source":["## Custom Data Loader"]},{"cell_type":"markdown","metadata":{"id":"c63xAKQBCl7c","colab_type":"text"},"source":["### Loader for grayscale images"]},{"cell_type":"code","metadata":{"id":"39tUxII3hrWx","colab_type":"code","colab":{}},"source":["train_dataset_Grayscale = MyDataset_Grayscale(csv_path='/content/drive/My Drive/STAT 479 Project/TrainingCorrect_combinedULcases.csv',\n","                                              img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                              transform=train_transforms_Grayscale)\n","train_loader_Grayscale = DataLoader(dataset=train_dataset_Grayscale,\n","                                    batch_size=BATCH_SIZE,\n","                                    shuffle=True, num_workers=4)\n","\n","valid_dataset_Grayscale = MyDataset_Grayscale(csv_path='/content/drive/My Drive/STAT 479 Project/ValidationCorrect_combinedULcases.csv',\n","                                              img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                              transform=valid_transforms_Grayscale)\n","valid_loader_Grayscale = DataLoader(dataset=valid_dataset_Grayscale,\n","                                    batch_size=BATCH_SIZE,\n","                                    shuffle=False, num_workers=4)\n","\n","test_dataset_Grayscale = MyDataset_Grayscale(csv_path='/content/drive/My Drive/STAT 479 Project/TestingCorrect_combinedULcases.csv',\n","                                             img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                             transform=test_transforms_Grayscale)\n","test_loader_Grayscale = DataLoader(dataset=test_dataset_Grayscale,\n","                                   batch_size=BATCH_SIZE,\n","                                   shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yYSrNS3iCpRp","colab_type":"text"},"source":["### Loader for binary images"]},{"cell_type":"code","metadata":{"id":"CAF1UoVGtgs8","colab_type":"code","colab":{}},"source":["train_dataset_Binary = MyDataset_Binary(csv_path='/content/drive/My Drive/STAT 479 Project/TrainingCorrect_combinedULcases.csv',\n","                                              img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                              transform=train_transforms_Binary)\n","train_loader_Binary = DataLoader(dataset=train_dataset_Binary,\n","                                    batch_size=BATCH_SIZE,\n","                                    shuffle=True, num_workers=4)\n","\n","valid_dataset_Binary = MyDataset_Binary(csv_path='/content/drive/My Drive/STAT 479 Project/ValidationCorrect_combinedULcases.csv',\n","                                              img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                              transform=valid_transforms_Binary)\n","valid_loader_Binary = DataLoader(dataset=valid_dataset_Binary,\n","                                    batch_size=BATCH_SIZE,\n","                                    shuffle=False, num_workers=4)\n","\n","test_dataset_Binary = MyDataset_Binary(csv_path='/content/drive/My Drive/STAT 479 Project/TestingCorrect_combinedULcases.csv',\n","                                             img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                             transform=test_transforms_Binary)\n","test_loader_Binary = DataLoader(dataset=test_dataset_Binary,\n","                                   batch_size=BATCH_SIZE,\n","                                   shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DlCmYYvfCs_C","colab_type":"text"},"source":["### Loader for RGB images"]},{"cell_type":"code","metadata":{"id":"gOXtkrEDiB8D","colab_type":"code","colab":{}},"source":["train_dataset_RGB = MyDataset_RGB(csv_path='/content/drive/My Drive/STAT 479 Project/TrainingCorrect_combinedULcases.csv',\n","                                  img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                  transform=train_transforms_RGB)\n","train_loader_RGB = DataLoader(dataset=train_dataset_RGB,\n","                              batch_size=BATCH_SIZE,\n","                              shuffle=True, num_workers=4)\n","\n","valid_dataset_RGB = MyDataset_RGB(csv_path='/content/drive/My Drive/STAT 479 Project/ValidationCorrect_combinedULcases.csv',\n","                                  img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                  transform=valid_transforms_RGB)\n","valid_loader_RGB = DataLoader(dataset=valid_dataset_RGB,\n","                              batch_size=BATCH_SIZE,\n","                              shuffle=False, num_workers=4)\n","\n","test_dataset_RGB = MyDataset_RGB(csv_path='/content/drive/My Drive/STAT 479 Project/TestingCorrect_combinedULcases.csv',\n","                                 img_dir='/content/drive/My Drive/STAT 479 Project/RenamedData',\n","                                 transform=test_transforms_RGB)\n","test_loader_RGB = DataLoader(dataset=test_dataset_RGB,\n","                              batch_size=BATCH_SIZE,\n","                              shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"I6hghKPxj5w0"},"source":["## Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_lza9t_uj5w1","colab":{}},"source":["##########################\n","### MODEL\n","##########################\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    \n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","      \n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes, grayscale):\n","        \n","        self.inplanes = 64\n","        \n","        if grayscale:\n","            in_dim = 1\n","        else:\n","            in_dim = 3\n","            \n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        \n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        \n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        \n","        self.fc1 = nn.Linear(512 * block.expansion, 512 * block.expansion)\n","        self.fcbn1 = nn.BatchNorm1d(512 * block.expansion)\n","        self.fcdropout1 = nn.Dropout(p=0.5)\n","        self.fc2 = nn.Linear(512 * block.expansion, 512)\n","        self.fcbn2 = nn.BatchNorm1d(512)\n","        self.fcdropout2 = nn.Dropout(p=0.5)\n","        self.fc3 = nn.Linear(512, NUM_CLASSES)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, (2. / n)**.5)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        # because our dataset is already 1x1 here:\n","        # disable avg pooling\n","        # x = self.avgpool(x)\n","        \n","        x = x.view(x.size(0), -1)\n","        x = self.fc1(x)\n","        x = self.fcbn1(x)\n","        x = F.relu(x)\n","        x = self.fcdropout1(x)\n","        x = self.fc2(x)\n","        x = self.fcbn2(x)\n","        x = F.relu(x)\n","        x = self.fcdropout2(x)\n","        logits = self.fc3(x)\n","        probas = F.softmax(logits, dim=1)\n","        return logits, probas\n","\n","  \n","def resnet50_RGB(num_classes):\n","    \"\"\"Constructs a ResNet-50 model, using RGB images as input.\"\"\"\n","    model = ResNet(block=Bottleneck,\n","                   layers=[3, 4, 6, 3],\n","                   num_classes=NUM_CLASSES,\n","                   grayscale=False)\n","    return model\n","\n","def resnet50_grayscale(num_classes):\n","    \"\"\"Constructs a ResNet-50 model, using grayscale images as input, either binary or not.\"\"\"\n","    model = ResNet(block=Bottleneck, \n","                   layers=[3, 4, 6, 3],\n","                   num_classes=NUM_CLASSES,\n","                   grayscale=True)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RAodboScj5w6"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"TBPUFWY5t7P5","colab_type":"code","colab":{}},"source":["### detail: if true, return the prediction output\n","\n","def compute_accuracy(model, data_loader, detail):\n","    model.eval()\n","    correct_pred, num_examples = 0, 0\n","    labels, predictions, result = [], [], []\n","    for i, (features, targets) in enumerate(data_loader):\n","            \n","        features = features.to(DEVICE)\n","        targets = targets.to(DEVICE)\n","\n","        logits, probas = model(features)\n","        _, predicted_labels = torch.max(probas, 1)\n","        \n","        num_examples += targets.size(0)\n","        correct_pred += (predicted_labels == targets).sum()\n","        if detail:\n","            targets = targets.cpu().numpy()\n","            predicted_labels = predicted_labels.cpu().numpy()\n","            labels = np.concatenate((labels, targets), axis=0)\n","            predictions = np.concatenate((predictions, predicted_labels), axis=0)\n","    if detail:\n","        return correct_pred.float()/num_examples * 100, labels, predictions\n","    else:\n","        return correct_pred.float()/num_examples * 100\n","\n","\n","def compute_epoch_loss(model, data_loader):\n","    model.eval()\n","    curr_loss, num_examples = 0., 0\n","    with torch.no_grad():\n","        for features, targets in data_loader:\n","            features = features.to(DEVICE)\n","            targets = targets.to(DEVICE)\n","            logits, probas = model(features)\n","            loss = F.cross_entropy(logits, targets, reduction='sum')\n","            num_examples += targets.size(0)\n","            curr_loss += loss\n","\n","        curr_loss = curr_loss / num_examples\n","        return curr_loss\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGPrpe5uADCL","colab_type":"text"},"source":["### ResNet-50 model taking RGB images as input\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Dzh3ROmRj5w7","colab":{}},"source":["torch.manual_seed(RANDOM_SEED)\n","\n","model = resnet50_RGB(NUM_CLASSES)\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","    \n","minibatch_cost, epoch_cost = [], []\n","\n","start_time = time.time()\n","\n","train_loader = train_loader_RGB\n","valid_loader = valid_loader_RGB\n","test_loader = test_loader_RGB\n","    \n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    for batch_idx, (features, targets) in enumerate(train_loader):\n","        \n","        features = features.to(DEVICE)\n","        targets = targets.to(DEVICE)\n","            \n","        ### FORWARD AND BACK PROP\n","        logits, probas = model(features)\n","        cost = F.cross_entropy(logits, targets)\n","        optimizer.zero_grad()\n","        \n","        cost.backward()\n","        minibatch_cost.append(cost)\n","        \n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        ### LOGGING\n","        if not batch_idx % 50:\n","            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n","                   %(epoch+1, NUM_EPOCHS, batch_idx, \n","                     len(train_loader), cost))\n","\n","    model.eval()\n","    with torch.set_grad_enabled(False): # save memory during inference\n","        if not (epoch+1) % 10:\n","            cost = compute_epoch_loss(model, train_loader)\n","            epoch_cost.append(cost)\n","            train_acc = compute_accuracy(model, train_loader, detail = False)\n","            valid_acc = compute_accuracy(model, valid_loader, detail = False)\n","            \n","            print('Epoch: %03d/%03d | Train Cost: %.4f' % (epoch+1, NUM_EPOCHS, cost))\n","            print('Train Accuracy: %.3f%% | Validation Accuracy: %.3f%%' % (train_acc, valid_acc))\n","            \n","    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n","    \n","print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n","with torch.set_grad_enabled(False): # save memory during inference\n","    test_accuracy, labels, predictions = compute_accuracy(model, test_loader, detail=True)\n","    print('Test accuracy: %.2f%%' % (test_accuracy))\n","    \n","plt.plot(range(len(minibatch_cost)), minibatch_cost)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.ylim([0, 4])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KTv5WOy8TPn6","colab_type":"code","colab":{}},"source":["del model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KHc6rxhZAJdP","colab_type":"text"},"source":["### ResNet-50 model taking RGB images as input running for 50 epochs"]},{"cell_type":"code","metadata":{"id":"sxFHdOMkNGlg","colab_type":"code","colab":{}},"source":["NUM_EPOCHS = 50\n","\n","torch.manual_seed(RANDOM_SEED)\n","\n","model = resnet50_RGB(NUM_CLASSES)\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","    \n","minibatch_cost, epoch_cost = [], []\n","\n","start_time = time.time()\n","\n","train_loader = train_loader_RGB\n","valid_loader = valid_loader_RGB\n","test_loader = test_loader_RGB\n","    \n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    for batch_idx, (features, targets) in enumerate(train_loader):\n","        \n","        features = features.to(DEVICE)\n","        targets = targets.to(DEVICE)\n","            \n","        ### FORWARD AND BACK PROP\n","        logits, probas = model(features)\n","        cost = F.cross_entropy(logits, targets)\n","        optimizer.zero_grad()\n","        \n","        cost.backward()\n","        minibatch_cost.append(cost)\n","        \n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        ### LOGGING\n","        if not batch_idx % 50:\n","            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n","                   %(epoch+1, NUM_EPOCHS, batch_idx, \n","                     len(train_loader), cost))\n","\n","    model.eval()\n","    with torch.set_grad_enabled(False): # save memory during inference\n","        if not (epoch+1) % 10:\n","            cost = compute_epoch_loss(model, train_loader)\n","            epoch_cost.append(cost)\n","            train_acc = compute_accuracy(model, train_loader, detail = False)\n","            valid_acc = compute_accuracy(model, valid_loader, detail = False)\n","            \n","            print('Epoch: %03d/%03d | Train Cost: %.4f' % (epoch+1, NUM_EPOCHS, cost))\n","            print('Train Accuracy: %.3f%% | Validation Accuracy: %.3f%%' % (train_acc, valid_acc))\n","            \n","    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n","    \n","print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n","with torch.set_grad_enabled(False): # save memory during inference\n","    test_accuracy, labels, predictions = compute_accuracy(model, test_loader, detail=True)\n","    print('Test accuracy: %.2f%%' % (test_accuracy))\n","    \n","plt.plot(range(len(minibatch_cost)), minibatch_cost)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.ylim([0, 4])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AqNZbi5qM5Cq","colab_type":"code","colab":{}},"source":["def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n","    csv = df.to_csv()\n","    b64 = base64.b64encode(csv.encode())\n","    payload = b64.decode()\n","    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n","    html = html.format(payload=payload,title=title,filename=filename)\n","    return HTML(html)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1VAk9zWM55r","colab_type":"code","colab":{}},"source":["CNN_RGB = pd.DataFrame({'Targets':labels, 'Predictions':predictions, 'Correct':np.array(predictions == labels)})\n","create_download_link(CNN_RGB, filename=\"CNN_RGB_50.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D3Q6EmudTSsh","colab_type":"code","colab":{}},"source":["del model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxytlHuIAZ-P","colab_type":"text"},"source":["### ResNet-50 model taking grayscale images as input"]},{"cell_type":"code","metadata":{"id":"iDbEzSTjmMuF","colab_type":"code","colab":{}},"source":["torch.manual_seed(RANDOM_SEED)\n","\n","model = resnet50_grayscale(NUM_CLASSES)\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","    \n","minibatch_cost, epoch_cost = [], []\n","\n","train_loader = train_loader_Grayscale\n","valid_loader = valid_loader_Grayscale\n","test_loader = test_loader_Grayscale\n","\n","start_time = time.time()\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    for batch_idx, (features, targets) in enumerate(train_loader):\n","        \n","        features = features.to(DEVICE)\n","        targets = targets.to(DEVICE)\n","            \n","        ### FORWARD AND BACK PROP\n","        logits, probas = model(features)\n","        cost = F.cross_entropy(logits, targets)\n","        optimizer.zero_grad()\n","        \n","        cost.backward()\n","        minibatch_cost.append(cost)\n","        \n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        ### LOGGING\n","        if not batch_idx % 50:\n","            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n","                   %(epoch+1, NUM_EPOCHS, batch_idx, \n","                     len(train_loader), cost))\n","\n","    model.eval()\n","    with torch.set_grad_enabled(False): # save memory during inference\n","        if not (epoch+1) % 10:\n","            cost = compute_epoch_loss(model, train_loader)\n","            epoch_cost.append(cost)\n","            train_acc = compute_accuracy(model, train_loader, detail = False)\n","            valid_acc = compute_accuracy(model, valid_loader, detail = False)\n","            \n","            print('Epoch: %03d/%03d | Train Cost: %.4f' % (epoch+1, NUM_EPOCHS, cost))\n","            print('Train Accuracy: %.3f%% | Validation Accuracy: %.3f%%' % (train_acc, valid_acc))\n","            \n","    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n","    \n","print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n","with torch.set_grad_enabled(False): # save memory during inference\n","    test_accuracy, labels, predictions = compute_accuracy(model, test_loader, detail=True)\n","    print('Test accuracy: %.2f%%' % (test_accuracy))\n","    \n","plt.plot(range(len(minibatch_cost)), minibatch_cost)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.ylim([0, 4])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CY6KVPnVTWxl","colab_type":"code","colab":{}},"source":["del model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pB7fuUu5Acio","colab_type":"text"},"source":["### ResNet-50 model taking binary grayscale images as input"]},{"cell_type":"code","metadata":{"id":"TqkirIpxmYc0","colab_type":"code","colab":{}},"source":["torch.manual_seed(RANDOM_SEED)\n","\n","model = resnet50_grayscale(NUM_CLASSES)\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","\n","train_loader = train_loader_Binary\n","valid_loader = valid_loader_Binary\n","test_loader = test_loader_Binary\n","    \n","minibatch_cost, epoch_cost = [], []\n","\n","start_time = time.time()\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    for batch_idx, (features, targets) in enumerate(train_loader):\n","        \n","        features = features.to(DEVICE)\n","        targets = targets.to(DEVICE)\n","            \n","        ### FORWARD AND BACK PROP\n","        logits, probas = model(features)\n","        cost = F.cross_entropy(logits, targets)\n","        optimizer.zero_grad()\n","        \n","        cost.backward()\n","        minibatch_cost.append(cost)\n","        \n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        ### LOGGING\n","        if not batch_idx % 50:\n","            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n","                   %(epoch+1, NUM_EPOCHS, batch_idx, \n","                     len(train_loader), cost))\n","\n","    model.eval()\n","    with torch.set_grad_enabled(False): # save memory during inference\n","        if not (epoch+1) % 10:\n","            cost = compute_epoch_loss(model, train_loader)\n","            epoch_cost.append(cost)\n","            train_acc = compute_accuracy(model, train_loader, detail = False)\n","            valid_acc = compute_accuracy(model, valid_loader, detail = False)\n","            \n","            print('Epoch: %03d/%03d | Train Cost: %.4f' % (epoch+1, NUM_EPOCHS, cost))\n","            print('Train Accuracy: %.3f%% | Validation Accuracy: %.3f%%' % (train_acc, valid_acc))\n","            \n","    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n","    \n","print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n","with torch.set_grad_enabled(False): # save memory during inference\n","    test_accuracy, labels, predictions = compute_accuracy(model, test_loader, detail=True)\n","    print('Test accuracy: %.2f%%' % (test_accuracy))\n","    \n","plt.plot(range(len(minibatch_cost)), minibatch_cost)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.ylim([0, 5])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3GIRBKnLTYqj","colab_type":"code","colab":{}},"source":["del model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H0dsTgmnAfGj","colab_type":"text"},"source":["### ResNet-50 model taking binary grayscale images as input running for 50 epochs"]},{"cell_type":"code","metadata":{"id":"GofYhOmWOeNU","colab_type":"code","colab":{}},"source":["NUM_EPOCHS = 50\n","\n","torch.manual_seed(RANDOM_SEED)\n","\n","model = resnet50_grayscale(NUM_CLASSES)\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","\n","train_loader = train_loader_Binary\n","valid_loader = valid_loader_Binary\n","test_loader = test_loader_Binary\n","    \n","minibatch_cost, epoch_cost = [], []\n","\n","start_time = time.time()\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    for batch_idx, (features, targets) in enumerate(train_loader):\n","        \n","        features = features.to(DEVICE)\n","        targets = targets.to(DEVICE)\n","            \n","        ### FORWARD AND BACK PROP\n","        logits, probas = model(features)\n","        cost = F.cross_entropy(logits, targets)\n","        optimizer.zero_grad()\n","        \n","        cost.backward()\n","        minibatch_cost.append(cost)\n","        \n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        ### LOGGING\n","        if not batch_idx % 50:\n","            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n","                   %(epoch+1, NUM_EPOCHS, batch_idx, \n","                     len(train_loader), cost))\n","\n","    model.eval()\n","    with torch.set_grad_enabled(False): # save memory during inference\n","        if not (epoch+1) % 10:\n","            cost = compute_epoch_loss(model, train_loader)\n","            epoch_cost.append(cost)\n","            train_acc = compute_accuracy(model, train_loader, detail = False)\n","            valid_acc = compute_accuracy(model, valid_loader, detail = False)\n","            \n","            print('Epoch: %03d/%03d | Train Cost: %.4f' % (epoch+1, NUM_EPOCHS, cost))\n","            print('Train Accuracy: %.3f%% | Validation Accuracy: %.3f%%' % (train_acc, valid_acc))\n","            \n","    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n","    \n","print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n","with torch.set_grad_enabled(False): # save memory during inference\n","    test_accuracy, labels, predictions = compute_accuracy(model, test_loader, detail=True)\n","    print('Test accuracy: %.2f%%' % (test_accuracy))\n","    \n","plt.plot(range(len(minibatch_cost)), minibatch_cost)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.ylim([0, 5])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DVNbB0UOYdO","colab_type":"code","colab":{}},"source":["CNN_Binary = pd.DataFrame({'Targets':labels, 'Predictions':predictions, 'Correct':np.array(predictions == labels)})\n","create_download_link(CNN_Binary, filename=\"CNN_Binary_50.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eFXhRA4TbBM","colab_type":"code","colab":{}},"source":["del model"],"execution_count":0,"outputs":[]}]}