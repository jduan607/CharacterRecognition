{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP Model using 52-class Dataset.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZVnbt_mtJkkA","colab_type":"text"},"source":["# I. Inspecting Dataset"]},{"cell_type":"code","metadata":{"trusted":true,"id":"2-tahWCCJkkB","colab_type":"code","colab":{}},"source":["import os\n","#os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n","import time\n","import torch\n","import base64\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from IPython.display import HTML\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision import models\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CaO7XFi5JkkF","colab_type":"text"},"source":["# II. Custom Dataset Class"]},{"cell_type":"code","metadata":{"trusted":true,"id":"0wQYkli0JkkG","colab_type":"code","colab":{}},"source":["##########################\n","### SETTINGS\n","##########################\n","\n","# Device\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Hyperparameters\n","RANDOM_SEED = 479\n","LEARNING_RATE = 0.1\n","NUM_EPOCHS = 30\n","BATCH_SIZE = 256\n","\n","# Architecture\n","NUM_FEATURES = 64*64\n","NUM_CLASSES = 52"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"II8fmXaxJkkH","colab_type":"text"},"source":["### Grayscale Images"]},{"cell_type":"code","metadata":{"trusted":true,"id":"pKH6mXlaJkkI","colab_type":"code","colab":{}},"source":["class MyDataset_Grayscale(Dataset):\n","\n","    def __init__(self, csv_path, img_dir, transform=None):\n","        df = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.img_names = df['File Name']\n","        self.y = df['Class Label']\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir, self.img_names[index]))\n","          \n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        label = self.y[index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q44Z9utWJkkJ","colab_type":"text"},"source":["### Binary Datasets"]},{"cell_type":"code","metadata":{"trusted":true,"id":"poWlgTM-JkkK","colab_type":"code","colab":{}},"source":["class MyDataset_Binary(Dataset):\n","\n","    def __init__(self, csv_path, img_dir, transform=None):\n","    \n","        df = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.img_names = df['File Name']\n","        self.y = df['Class Label']\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir,\n","                                      self.img_names[index]))\n","        \n","        img=img.convert(\"L\")\n","        threshold = 128\n","        # if pixel value smaller than threshold, return 0 . Otherwise return 1.\n","        filter_func = lambda x: 0 if x < threshold else 1\n","        img=img.point(filter_func, \"1\")\n","          \n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        label = self.y[index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V1XsIPaqJkkM","colab_type":"text"},"source":["### RGB"]},{"cell_type":"code","metadata":{"trusted":true,"id":"5Hdxz7U_JkkM","colab_type":"code","colab":{}},"source":["class MyDataset_RGB(Dataset):\n","\n","    def __init__(self, csv_path, img_dir, transform=None):\n","        df = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.img_names = df['File Name']\n","        self.y = df['Class Label']\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.img_dir, self.img_names[index]))\n","        \n","        # make 1 color channel to 3 \n","        ary = np.array(img)\n","        if len(ary.shape) < 3:\n","          ary = np.stack((ary,)*3,axis=-1)\n","          img = Image.fromarray(ary, 'RGB')\n","                    \n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        label = self.y[index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.y.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LyOrRkKPJkkO","colab_type":"text"},"source":["# III. Data Augmentation"]},{"cell_type":"markdown","metadata":{"id":"lNFLh4GVJkkP","colab_type":"text"},"source":["### Grayscale Images"]},{"cell_type":"code","metadata":{"trusted":true,"id":"dDD3BWP6JkkP","colab_type":"code","colab":{}},"source":["train_transforms_Grayscale = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.RandomAffine(degrees=(-20, 20), translate=(0.15, 0.15),\n","                                        resample=Image.BILINEAR),\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","valid_transforms_Grayscale = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_Grayscale = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_yXqWJkkJkkT","colab_type":"text"},"source":["### Binary Datasets"]},{"cell_type":"code","metadata":{"trusted":true,"id":"x2HB0NORJkkT","colab_type":"code","colab":{}},"source":["train_transforms_Binary = transforms.Compose([\n","    transforms.RandomAffine(degrees=(-20, 20), translate=(0.15, 0.15),\n","                                      resample=Image.BILINEAR),\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","valid_transforms_Binary = transforms.Compose([\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_Binary = transforms.Compose([\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2KQO-1WFJkkV","colab_type":"text"},"source":["### RGB"]},{"cell_type":"code","metadata":{"trusted":true,"id":"tevYX60dJkkW","colab_type":"code","colab":{}},"source":["train_transforms_RGB = transforms.Compose([\n","    transforms.RandomAffine(degrees=(-20, 20), translate=(0.15, 0.15),\n","                                      resample=Image.BILINEAR),\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","valid_transforms_RGB = transforms.Compose([\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_RGB = transforms.Compose([\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uk4TMnnIJkkX","colab_type":"text"},"source":["# IV. Custom Data Loader"]},{"cell_type":"markdown","metadata":{"id":"rgnqJIgbJkkY","colab_type":"text"},"source":["### Grayscale Images"]},{"cell_type":"code","metadata":{"trusted":true,"id":"kw_gq4wIJkkY","colab_type":"code","colab":{}},"source":["train_dataset_Grayscale = MyDataset_Grayscale(csv_path='../input/stat479csv/TrainingGood.csv',\n","                                              img_dir='../input/stat479project/data',\n","                                              transform=train_transforms_Grayscale)\n","\n","train_loader_Grayscale = DataLoader(dataset=train_dataset_Grayscale,\n","                                    batch_size=BATCH_SIZE,\n","                                    shuffle=True, num_workers=4)\n","\n","valid_dataset_Grayscale = MyDataset_Grayscale(csv_path='../input/stat479csv/ValidationGood.csv',\n","                                              img_dir='../input/stat479project/data',\n","                                              transform=valid_transforms_Grayscale)\n","\n","valid_loader_Grayscale = DataLoader(dataset=valid_dataset_Grayscale,\n","                                    batch_size=BATCH_SIZE,\n","                                    shuffle=False, num_workers=4)\n","\n","test_dataset_Grayscale = MyDataset_Grayscale(csv_path='../input/stat479csv/TestingGood.csv',\n","                                             img_dir='../input/stat479project/data',\n","                                             transform=test_transforms_Grayscale)\n","\n","test_loader_Grayscale = DataLoader(dataset=test_dataset_Grayscale,\n","                                   batch_size=BATCH_SIZE,\n","                                   shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swdFzqljJkka","colab_type":"text"},"source":["### Binary Datasets"]},{"cell_type":"code","metadata":{"trusted":true,"id":"_NF3cilDJkka","colab_type":"code","colab":{}},"source":["train_dataset_Binary = MyDataset_Binary(csv_path='../input/stat479csv/TrainingGood.csv',\n","                          img_dir='../input/stat479project/data',\n","                          transform=train_transforms_Binary)\n","\n","train_loader_Binary = DataLoader(dataset=train_dataset_Binary,\n","                          batch_size=256,\n","                          shuffle=True, # want to shuffle the dataset\n","                          num_workers=4) # number processes/CPUs to use\n","\n","valid_dataset_Binary = MyDataset_Binary(csv_path='../input/stat479csv/ValidationGood.csv',\n","                          img_dir='../input/stat479project/data',\n","                          transform=valid_transforms_Binary)\n","\n","valid_loader_Binary = DataLoader(dataset=valid_dataset_Binary,\n","                          batch_size=256,\n","                          shuffle=False, \n","                          num_workers=4) # number processes/CPUs to use\n","\n","test_dataset_Binary = MyDataset_Binary(csv_path='../input/stat479csv/TestingGood.csv',\n","                          img_dir='../input/stat479project/data',\n","                          transform=test_transforms_Binary)\n","\n","test_loader_Binary = DataLoader(dataset=test_dataset_Binary,\n","                          batch_size=256,\n","                          shuffle=False, \n","                          num_workers=4) # number processes/CPUs to use"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ogMqzQ5QJkkc","colab_type":"text"},"source":["### RGB"]},{"cell_type":"code","metadata":{"trusted":true,"id":"sEnqfXMIJkkc","colab_type":"code","colab":{}},"source":["train_dataset_RGB = MyDataset_RGB(csv_path='../input/stat479csv/TrainingGood.csv',\n","                                  img_dir='../input/stat479project/data',\n","                                  transform=train_transforms_RGB)\n","\n","train_loader_RGB = DataLoader(dataset=train_dataset_RGB,\n","                              batch_size=BATCH_SIZE,\n","                              shuffle=True, num_workers=4)\n","\n","valid_dataset_RGB = MyDataset_RGB(csv_path='../input/stat479csv/ValidationGood.csv',\n","                                  img_dir='../input/stat479project/data',\n","                                  transform=valid_transforms_RGB)\n","\n","valid_loader_RGB = DataLoader(dataset=valid_dataset_RGB,\n","                              batch_size=BATCH_SIZE,\n","                              shuffle=False, num_workers=4)\n","\n","test_dataset_RGB = MyDataset_RGB(csv_path='../input/stat479csv/TestingGood.csv',\n","                                 img_dir='../input/stat479project/data',\n","                                 transform=test_transforms_RGB)\n","\n","test_loader_RGB = DataLoader(dataset=test_dataset_RGB,\n","                              batch_size=BATCH_SIZE,\n","                              shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yrICqHGVJkkp","colab_type":"text"},"source":["> # VI. MLP"]},{"cell_type":"markdown","metadata":{"id":"lCvW69D_Jkkp","colab_type":"text"},"source":["### 1. Settings"]},{"cell_type":"code","metadata":{"trusted":true,"id":"hpH1jT-1Jkkq","colab_type":"code","colab":{}},"source":["def compute_epoch_loss_MLP(model, data_loader):\n","    curr_loss, num_examples = 0., 0\n","    \n","    with torch.no_grad():\n","        for features, targets in data_loader:\n","            if GRAYSCALE:\n","                features = features.view(-1,NUM_FEATURES).to(DEVICE)\n","            else:\n","                features = features.view(-1,NUM_FEATURES*3).to(DEVICE)\n","            targets = targets.to(DEVICE)\n","            logits, probas = model.forward(features)\n","            loss = F.cross_entropy(logits, targets, reduction='sum')\n","            num_examples += targets.size(0)\n","            curr_loss += loss\n","\n","        curr_loss = curr_loss / num_examples\n","        return curr_loss\n","    \n","    \n","def compute_accuracy_MLP(model, data_loader, detail):\n","    correct_pred, num_examples = 0, 0\n","    labels, predictions, result = [], [], []\n","    \n","    with torch.no_grad():\n","        for features, targets in data_loader:\n","            if GRAYSCALE:\n","                features = features.view(-1,NUM_FEATURES).to(DEVICE)\n","            else:\n","                features = features.view(-1,NUM_FEATURES*3).to(DEVICE)\n","            targets = targets.to(DEVICE)\n","            logits, probas = model.forward(features)\n","            predicted_labels = torch.argmax(probas, 1)\n","            num_examples += targets.size(0)\n","            correct_pred += (predicted_labels == targets).sum()\n","            if detail:\n","                targets = targets.cpu().numpy()\n","                predicted_labels = predicted_labels.cpu().numpy()\n","                labels = np.concatenate((labels, targets), axis=0)\n","                predictions = np.concatenate((predictions, predicted_labels), axis=0)\n","        if detail:\n","            return correct_pred.float()/num_examples * 100, labels, predictions\n","        else:\n","            return correct_pred.float()/num_examples * 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ixlm1RlcJkks","colab_type":"code","colab":{}},"source":["def train_MLP(model, train_loader, valid_loader, test_loader):\n","    minibatch_cost, epoch_cost = [], []\n","    start_time = time.time()\n","    for epoch in range(NUM_EPOCHS):\n","        model.train()\n","    \n","        for batch_idx, (features, targets) in enumerate(train_loader):\n","            if GRAYSCALE:\n","                features = features.view(-1,NUM_FEATURES).to(DEVICE)\n","            else:\n","                features = features.view(-1,NUM_FEATURES*3).to(DEVICE)\n","            targets = targets.to(DEVICE)\n","      \n","            logits, probas = model.forward(features)\n","            cost = F.cross_entropy(logits, targets)\n","            optimizer.zero_grad()\n","      \n","            cost.backward()\n","            minibatch_cost.append(cost)\n","            optimizer.step()\n","       \n","            if not batch_idx % 50:\n","                print('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f'\n","                      %(epoch+1, NUM_EPOCHS, batch_idx, len(train_loader), cost))\n","        model.eval()\n","        with torch.set_grad_enabled(False):\n","            if not (epoch+1) % 10:\n","                cost = compute_epoch_loss_MLP(model, train_loader)\n","                epoch_cost.append(cost)\n","                train_accuracy = compute_accuracy_MLP(model, train_loader, detail=False)\n","                valid_accuracy = compute_accuracy_MLP(model, valid_loader, detail=False)\n","                print('Epoch: %03d/%03d | Train Cost: %.4f' % (epoch+1, NUM_EPOCHS, cost))\n","                print('Train Accuracy: %.3f%% | Validation Accuracy: %.3f%%' % (train_accuracy, valid_accuracy))\n","   \n","        print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n","    \n","    print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n","    with torch.set_grad_enabled(False): # save memory during inference\n","        test_accuracy, labels, predictions = compute_accuracy_MLP(model, test_loader, detail=True)\n","        print('Test accuracy: %.2f%%' % (test_accuracy))\n","    \n","    return minibatch_cost, epoch_cost, labels, predictions"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d2wWlPKlJkkv","colab_type":"text"},"source":["### 2. Grayscale MLP: Softmax regression with 2-layer ReLU, Dropout, and BatchNorm"]},{"cell_type":"code","metadata":{"trusted":true,"id":"NKBn1nchJkkw","colab_type":"code","colab":{}},"source":["class MLP1(nn.Module):\n","  def __init__(self, num_features, drop_proba, \n","               num_hidden1, num_hidden2, num_classes):\n","    super(MLP1, self).__init__()\n","    \n","    self.network = nn.Sequential(\n","        nn.Linear(num_features, num_hidden1),\n","        nn.BatchNorm1d(num_hidden1), \n","        nn.ReLU(),\n","        nn.Dropout(drop_proba),\n","        nn.Linear(num_hidden1, num_hidden2),\n","        nn.BatchNorm1d(num_hidden2),\n","        nn.ReLU(),\n","        nn.Dropout(drop_proba),\n","        nn.Linear(num_hidden2, num_classes)\n","    )  \n","   \n","  def forward(self, x):\n","    logits = self.network(x)\n","    probas = F.softmax(logits, dim=1)\n","    return logits, probas\n","        \n","torch.manual_seed(RANDOM_SEED)\n","model1 = MLP1(num_features=NUM_FEATURES, \n","              drop_proba=0.2,\n","              num_hidden1=1000,\n","              num_hidden2=1000,\n","              num_classes=NUM_CLASSES)\n","\n","model1 = model1.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model1.parameters(), lr=LEARNING_RATE)\n","\n","GRAYSCALE=True\n","\n","minibatch_cost1, epoch_cost1, labels1, predictions1 = train_MLP(model1, train_loader_Binary, \n","                                                                valid_loader_Binary, test_loader_Binary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQQ4NfA0-JIQ","colab_type":"code","colab":{}},"source":["plt.plot(range(len(minibatch_cost1)), minibatch_cost1)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDvLd0biOr7s","colab_type":"code","colab":{}},"source":["def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n","    csv = df.to_csv()\n","    b64 = base64.b64encode(csv.encode())\n","    payload = b64.decode()\n","    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n","    html = html.format(payload=payload,title=title,filename=filename)\n","    return HTML(html)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wk6clypyOvlx","colab_type":"code","colab":{}},"source":["mlp_grayscale = pd.DataFrame({'Targets':labels1, 'Predictions':predictions1, 'Correct':np.array(predictions1 == labels1)})\n","create_download_link(mlp_grayscale, filename=\"MLP_Grayscale_52Class.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8BjwF7bJkk0","colab_type":"text"},"source":["### Binary MLP"]},{"cell_type":"code","metadata":{"trusted":true,"id":"A_3tF0XnJkk1","colab_type":"code","colab":{}},"source":["class MLP2(nn.Module):\n","  def __init__(self, num_features, drop_proba, \n","               num_hidden1, num_hidden2, num_classes):\n","    super(MLP2, self).__init__()\n","    \n","    self.network = nn.Sequential(\n","        nn.Linear(num_features, num_hidden1),\n","        nn.BatchNorm1d(num_hidden1), \n","        nn.ReLU(),\n","        nn.Dropout(drop_proba),\n","        nn.Linear(num_hidden1, num_hidden2),\n","        nn.BatchNorm1d(num_hidden2),\n","        nn.ReLU(),\n","        nn.Dropout(drop_proba),\n","        nn.Linear(num_hidden2, num_classes)\n","    )  \n","   \n","  def forward(self, x):\n","    logits = self.network(x)\n","    probas = F.softmax(logits, dim=1)\n","    return logits, probas\n","        \n","torch.manual_seed(RANDOM_SEED)\n","model2 = MLP2(num_features=NUM_FEATURES, \n","              drop_proba=0.2,\n","              num_hidden1=1000,\n","              num_hidden2=1000,\n","              num_classes=NUM_CLASSES)\n","\n","model2 = model2.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model2.parameters(), lr=LEARNING_RATE)\n","\n","GRAYSCALE=True\n","\n","minibatch_cost2, epoch_cost2, labels2, predictions2 = train_MLP(model2, train_loader_Binary, valid_loader_Binary, test_loader_Binary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"Od-_-NNEJkk2","colab_type":"code","colab":{}},"source":["plt.plot(range(len(minibatch_cost2)), minibatch_cost2)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4Etqhh9O5QS","colab_type":"text"},"source":["## RGB MLP"]},{"cell_type":"code","metadata":{"id":"7EPCm6oBO66T","colab_type":"code","colab":{}},"source":["class MLP3(nn.Module):\n","  def __init__(self, num_features, drop_proba, \n","               num_hidden1, num_hidden2, num_classes):\n","    super(MLP3, self).__init__()\n","    \n","    self.network = nn.Sequential(\n","        nn.Linear(num_features, num_hidden1),\n","        nn.BatchNorm1d(num_hidden1), \n","        nn.ReLU(),\n","        nn.Dropout(drop_proba),\n","        nn.Linear(num_hidden1, num_hidden2),\n","        nn.BatchNorm1d(num_hidden2),\n","        nn.ReLU(),\n","        nn.Dropout(drop_proba),\n","        nn.Linear(num_hidden2, num_classes)\n","    )  \n","   \n","  def forward(self, x):\n","    logits = self.network(x)\n","    probas = F.softmax(logits, dim=1)\n","    return logits, probas\n","        \n","torch.manual_seed(RANDOM_SEED)\n","model3 = MLP3(num_features=NUM_FEATURES*3, \n","              drop_proba=0.2,\n","              num_hidden1=3000,\n","              num_hidden2=1500,\n","              num_classes=NUM_CLASSES)\n","\n","model3 = model3.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(model3.parameters(), lr=LEARNING_RATE)\n","\n","GRAYSCALE=False\n","\n","minibatch_cost3, epoch_cost3, labels3, predictions3 = train_MLP(model3, train_loader_RGB, valid_loader_RGB, test_loader_RGB)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2yg7_cQPbA4","colab_type":"code","colab":{}},"source":["plt.plot(range(len(minibatch_cost3)), minibatch_cost3)\n","plt.ylabel('Cross Entropy')\n","plt.xlabel('Minibatch')\n","plt.show()"],"execution_count":0,"outputs":[]}]}